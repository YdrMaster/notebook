# Unikraft：构造快速、专用的幺内核的简单方法

> Unikraft: Fast, Specialized Unikernels the Easy Way

---

> [原文](https://dl.acm.org/doi/pdf/10.1145/3447786.3456248)

## 译文对照表

| 原文 | 译文
| :-: | :-:
| unikernel | 幺内核
| micro-library | 微库

## 摘要

> Abstract

幺内核因在启动时间、吞吐量和内存消耗等方面提供出色的性能而闻名，这里仅举几个指标。然而，它们因使提取这种性能变得困难和极其耗时而臭名昭著，并且需要大量的工程努力才能将应用程序移植到它们上面。我们推出 Unikraft，一个新颖的微库操作系统：（1）完全模块化的操作系统基元，因此很容易定制幺内核并只包括相关的组件；（2）暴露了一套可组合的、面向性能的 API，以便使开发者容易获得高性能。我们使用现成的应用程序（如 nginx、SQLite 和 Redis）进行的评估表明，在 Unikraft 上运行它们，与 Linux 虚拟机相比，性能提高了 1.7-2.7 倍。此外，这些应用的 Unikraft 镜像约为 1MB，运行时需要不到 10MB 的内存，在 VMM 时间之外，启动时间约为 1ms（总启动时间为 3-40 ms）。Unikraft 是 Linux 基金会的一个开源项目，可以在 <https://www.unikraft.org> 找到。

> Unikernels are famous for providing excellent performance in terms of boot times, throughput and memory consumption, to name a few metrics. However, they are infamous for making it hard and extremely time consuming to extract such performance, and for needing significant engineering effort in order to port applications to them. We introduce Unikraft, a novel micro-library OS that (1) fully modularizes OS primitives so that it is easy to customize the unikernel and include only relevant components and (2) exposes a set of composable, performance-oriented APIs in order to make it easy for developers to obtain high performance. Our evaluation using off-the-shelf applications such as nginx, SQLite, and Redis shows that running them on Unikraft results in a 1.7x-2.7x performance improvement compared to Linux guests. In addition, Unikraft images for these apps are around 1MB, require less than 10MB of RAM to run, and boot in around 1ms on top of the VMM time (total boot time 3ms-40ms). Unikraft is a Linux Foundation open source project and can be found at www.unikraft.org.

## 1 引言

> 1 Introduction

可以说，专用化是实现卓越性能的最有效方式，无论是在网络相关的应用中实现高吞吐量\[38, 50, 52\]，还是使语言运行环境更加高效\[20, 23, 47, 65\]，或者提供高效的容器环境\[62, 76\]，都可以举出一些例子。即使在硬件领域，特别是随着摩尔定律的消亡，制造商越来越倾向于硬件专化用，以实现越来越好的性能；这在机器学习领域尤为明显\[30, 32, 34\]。

> Specialization is arguably the most effective way to achieve outstanding performance, whether it is for achieving high throughput in network-bound applications \[38, 50, 52\], making language runtime environments more efficient \[20, 23, 47, 65\], or providing efficient container environments \[62, 76\], to give some examples. Even in the hardware domain, and especially with the demise of Moore’s law, manufacturers are increasingly leaning towards hardware specialization to achieve ever better performance; the machine learning field is a primary exponent of this \[30, 32, 34\].

在虚拟化领域，幺内核是专用化的黄金标准，在吞吐量、内存消耗和启动时间等方面显示出令人印象深刻的结果\[36, 40, 45, 47, 48\]。其中一些好处来自于拥有单一的内存地址空间，从而消除了昂贵的系统调用开销，但其中许多是能够在正确的抽象层次上绑定应用程序以获得最佳性能的结果：例如，一个旨在为每秒数百万个请求提供服务的网络服务器可以访问一个低层次的、基于批处理的网络 API，而不是标准但缓慢的套接字 API。这样的方法已经在一些幺内核项目中被采用，但往往是以一种临时的、即用即弃的方式\[38, 48, 52\]。总的来说，尽管有明显的好处，但幺内核仍有两个主要的缺点：

> In the virtualization domain, unikernels are the golden standard for specialization, showing impressive results in terms of throughput, memory consumption, and boot times, among others \[36, 40, 45, 47, 48\]. Some of those benefits come from having a single memory address space, thus eliminating costly syscall overheads, but many of those are the result of being able to hook the application at the right level of abstraction to extract best performance: for example, a web server aiming to service millions of requests per second can access a low-level, batch-based network API rather than the standard but slow socket API. Such an approach has been taken in several unikernel projects but often in an ad hoc, build-and-discard manner \[38, 48, 52\]. In all, despite clear benefits, unikernels suffer from two major drawbacks:

- 它们需要大量的专业工作来构建并优化出高性能；在大多数情况下，这种工作必须为每个目标应用重新进行。
- 它们通常不符合 POSIX 标准，需要移植应用程序和语言环境。

> - They require significant expert work to build and to extract high performance; such work has to, for the most part, be redone for each target application.
> - They are often non-POSIX compliant, requiring porting of applications and language environments.

我们认为这些缺点并不是根本性的，并提出了一个专门为解决这些问题而建立的幺内核架构。现有的幺内核项目，甚至是那些基于库架构的项目，往往是由小型但单一的内核组成，这些内核的组件具有复杂的、交织在一起的、有时不透明的 API。这意味着开发者不仅要经常将应用程序移植到这样的系统中，而且优化它们的性能需要深入研究代码和（幺）内核的具体情况，以了解如何最好地获得性能提升。

> We argue that these drawbacks are not fundamental, and propose a unikernel architecture built specifically to address them. Existing unikernel projects, even those based on library architectures, tend to consist of small but monolithic kernels that have complex, intertwined and sometimes opaque APIs for their components. This means that developers not only have to often port applications to such systems, but that optimizing their performance requires digging into the code and the specifics of the (uni)kernel in order to understand how to best obtain performance gains.

此外，这类系统通常依赖于面向尺寸的专用化：去除所有不必要的组件以实现最小的镜像。虽然这种策略已经提供了很大的好处，但我们认为，基于库架构的幺内核应该便于获得真正的专用化，允许用户为特定的应用、环境约束和关键性能指标选择最佳的系统组件。

> Further, such systems typically rely on size-based specialization: removing all unnecessary components to achieve minimal images. While this strategy already offers significant benefits, we argue that unikernels based on library architectures should ease access to true specialization, allowing users to choose the best system component for a given application, environmental constraints, and key performance indicators.

在本文中，我们提出了 Unikraft，一个新颖的微库操作系统，旨在无痛、无缝地生成专用化、高性能的幺内核。要做到这一点，Unikraft 依赖于两个关键原则：

> In this paper we propose Unikraft, a novel micro-library operating system targeted at painlessly and seamlessly generating specialized, high performance unikernels. To do so, Unikraft relies on two key principles:

- 内核应该是完全模块化的，以便使幺内核能够完全和容易地定制。在 Unikraft 中，诸如内存分配器、调度器、网络堆栈和早期启动代码等操作系统基元是独立的微库。
- 内核应该提供注重性能的、定义明确的 API，这些 API 可以很容易地被选择和组成，以满足应用程序的性能需求。在 Unikraft 中，这样的 API 本身就是微库，这意味着它们可以很容易地被加入或从构建中移除，而且它们的功能可以通过提供额外的这种微库来扩展。

> - The kernel should be fully modular in order to allow for the unikernel to be fully and easily customizable. In Unikraft, OS primitives such as memory allocators, schedulers, network stacks and early boot code are stand-alone micro-libraries.
> - The kernel should provide performance-minded, well-defined APIs that can be easily selected and composed in order to meet an application’s performance needs. In Unikraft, such APIs are micro-libraries themselves, meaning that they can be easily added to or removed from a build, and that their functionality can be extended by providing additional such micro-libraries.

简而言之，Unikraft 的关键概念创新是为操作系统核心组件定义了一套小的 API，当不需要的时候可以很容易地替换掉一个组件，面对不同性能需求可以从同一个组件的多个实现中挑选。构建 API 时考虑了性能（例如，通过设计支持批处理）和最小化（没有不需要的功能）。

> In brief, the key conceptual innovation of Unikraft is defining a small set of APIs for core OS components that makes it easy to replace-out a component when it is not needed, and to pick-and-choose from multiple implementations of the same component when performance dictates. The APIs have been built with performance (e.g., by supporting batching by design) and minimality in mind (no unneeded features).

为了支持广泛的应用，我们移植了 musl libc 库，并提供了一个系统调用 shim 层微库。因此，在 Unikraft 上运行一个应用程序可以像用其本地构建系统构建它一样简单，并将产生的对象文件链接回 Unikraft。此外，Unikraft 支持许多已经移植的应用程序（如 SQLite、nginx、Redis）、编程语言和运行环境，如 C/C++、Go、Python、Ruby、Web Assembly 和 Lua，以及一些不同的 Hypervisor/VMM（截至本文写作时，QEMU/KVM、Xen、Firecracker\[4\] 和 Solo5\[78\]）。

> To support a wide range of applications, we port the musl libc library, and provide a syscall shim layer micro-library. As a result, running an application on Unikraft can be as simple as building it with its native build system, and linking the resulting object files back into Unikraft. In addition, Unikraft supports a number of already-ported applications (e.g., SQLite, nginx, Redis), programming languages and runtime environments such as C/C++, Go, Python, Ruby, Web Assembly and Lua, and a number of different hypervisors/VMMs (QEMU/KVM, Xen, Firecracker \[4\], and Solo5 \[78\] as of this writing).

我们在 Unikraft 上使用此类应用的评估结果是，与 Linux 虚拟机相比，性能提高了 1.7-2.7 倍。此外，这些应用程序的 Unikraft 镜像约为 1MB，需要不到 10MB 内存来运行，并且在 VMM 时间之外，可以在 1ms 内启动（总启动时间 2-40 ms）。Unikraft 是 Linux 基金会的一个开源项目，其源代码可以在 <https://www.unikraft.org> 找到。

> Our evaluation using such applications on Unikraft results in a 1.7x-2.7x performance improvement compared to Linux guests. In addition, Unikraft images for these apps are around 1MB, require less than 10MB of RAM to run, and boot in around 1ms on top of the VMM time (total boot time 2ms-40ms). Unikraft is a Linux Foundation open source project and the sources can be found at www.unikraft.org.

## 2 设计理念和方案空间

> 2 Design Principles and Solution Space

在得出 Unikraft 的关键设计原则之前，值得分析一下传统操作系统中那些不必要的或不适合于单一应用案例的功能和（重量级）机制：

> Before deriving what the key design principles for Unikraft are, it is worth analyzing the features and (heavyweight) mechanisms of traditional OSes that are unnecessary or illsuited to single application use cases:

- 应用程序和内核之间的保护域切换在虚拟化环境下可能是多余的，因为隔离是由 Hypervisor 程序保证的，而且会导致可观的性能下降。
- 多个地址空间在单个应用域中可能是无用的，但在标准操作系统中取消这种支持需要大量工作来重新实现。
- 对于 RPC 风格的服务器应用，线程是不需要的，一个单一的、运行到完成的事件循环就足以实现高性能。这将消除对虚拟机内的调度器及其相关开销的需求，以及虚拟机和 Hypervisor 调度器之间的不匹配\[19\]。
- 对于以性能为导向的基于 UDP 的应用程序，操作系统网络协议栈的大部分都是无用的：应用程序可以简单地使用驱动 API，就像 DPDK 风格的应用程序已经做的那样。目前还没有办法从标准的操作系统中轻松删除网络协议栈而不是整个网络子系统。
- 应用程序直接访问 NVMe 存储，消除了对文件描述符、VFS 层和文件系统的需求，但从现有的操作系统中移除这种支持，包括围绕着存储 API 的多层结构，是非常困难的。
- 内存分配器对应用程序的性能有很大的影响，而通用分配器已经被证明对许多应用程序来说不是最优的\[66\]。因此，如果每个应用程序可以选择自己的分配器，那将是最理想的；然而，这在今天的操作系统中很难做到，因为内核所使用的分配器是内置的。

> - Protection-domain switches between the application and the kernel might be redundant in a virtualization context because isolation is ensured by the hypervisor, and result in measurable performance degradation.
> - Multiple address spaces may be useless in a single application domain, but removing such support in standard OSes requires a massive reimplementation effort.
> - For RPC-style server applications, threading is not needed, with a single, run-to-completion event loop sufficing for high performance. This would remove the need for a scheduler within the VM and its associated overheads, as well as the mismatch between the guest and hypervisor schedulers \[19\].
> - For performance-oriented UDP-based apps, much of the OS networking stack is useless: the app could simply use the driver API, much like DPDK-style applications already do. There is currently no way to easily remove just the network stack but not the entire network sub-system from standard OSes.
> - Direct access to NVMe storage from apps removes the need for file descriptors, a VFS layer and a filesystem, but removing such support from existing OSes, built around layers of the storage API, is very difficult.
> - Memory allocators have a large impact on application performance, and general purpose allocators have been shown to be suboptimal for many apps \[66\]. It would therefore be ideal if each app could choose its own allocator; this is however very difficult to do in today’s operating systems because the allocators that kernels use are baked in.

这个公认的、不完备的应用专用优化列表意味着，对于标准操作系统提供的每一个核心功能，至少存在一个或几个不需要它的应用。移除这样的功能会减少代码大小和资源使用，但往往需要进行重要的重新设计工作。

> This admittedly non-exhaustive list of application-specific optimizations implies that for each core functionality that a standard OS provides, there exists at least one or a few applications that do not need it. Removing such functionality would reduce code size and resource usage but would often require an important re-engineering effort.

我们想要解决的问题是使开发者能够为每一个应用程序创建一个专门的操作系统，以确保尽可能的最佳性能，同时约束与操作系统相关的开发工作，并使现有的应用程序易于移植。这一分析指出了一些关键的设计决策：

> The problem we want to solve is to enable developers to create a specialized OS for every single application to ensure the best performance possible, while at the same time bounding OS-related development effort and enabling easy porting of existing applications. This analysis points to a number of key design decisions:

- 单一地址空间：以单一应用场景为目标，可能有不同的应用通过网络通信交流。
- 完全模块化的系统：所有组件，包括操作系统基元、驱动程序、平台代码和库，都应该易于根据需要添加和删除；甚至 API 也应该是模块化的。
- 单一的特权级：不应该有用户/内核空间的分离，以避免昂贵的处理器模式切换。这并不排斥区隔化（例如微库），这可以以合理的开销实现\[69\]。
- 静态链接：启用编译器功能，例如死代码消除（DCE）和链接时优化（LTO），以自动摆脱不需要的代码。
- 支持 POSIX：为了支持现有的或遗留的应用程序和编程语言，同时仍允许在该 API 下实现专用化。
- 平台抽象化：为一系列不同的 Hypervisor/VMM 无缝生成镜像。

> - Single address space: Target single application scenarios, with possibly different applications talking to each other through networked communications.
> - Fully modular system: All components, including operating system primitives, drivers, platform code and libraries should be easy to add and remove as needed; even APIs should be modular.
> - Single protection level: There should be no user/kernel-space separation to avoid costly processor mode switches. This does not preclude compartmentalization (e.g., of micro-libraries), which can be achieved at reasonable cost \[69\].
> - Static linking: Enable compiler features, e.g., Dead Code Elimination (DCE) and Link-Time Optimization (LTO), to automatically get rid of unneeded code.
> - POSIX support: In order to support existing or legacy applications and programming languages while still allowing for specialization under that API.
> - Platform abstraction: Seamless generation of images for a range of different hypervisors/VMMs.

有鉴于此，问题在于如何实现这样一个系统：最小化现有的通用操作系统、从现有的幺内核项目开始，或者从头开始。

> Given these, the question is how to implement such a system: by minimizing an existing general-purpose operating system, by starting from an existing unikernel project, or from scratch.

现有的工作在解决这个问题方面有三个方向。第一个方向是采用现有的操作系统并增加或删除功能。主要的例子是增加对单一地址空间的支持和删除保护域的交叉。OSv \[37\]和 Rump \[36\]采用了 BSD 内核的部分内容，并重新设计了它以在幺内核环境下工作；Lupine Linux \[40\]依赖于 Linux 内核的最小化、专用化配置和内核模式 Linux（KML）补丁。这些方法使应用程序的移植变得容易，因为它们提供了二进制兼容性或 POSIX 兼容性，但所产生的内核是宏式的的。

> Existing work has taken three directions in tackling this problem. The first direction takes existing OSes and adds or removes functionality. Key examples add support for a single address space and remove protection domain crossings: OSv \[37\] and Rump \[36\] adopt parts of the BSD kernel and re-engineer it to work in a unikernel context; Lupine Linux \[40\] relies on a minimal, specialized configuration of the Linux kernel with Kernel Mode Linux (KML) patches. These approaches make application porting easy because they provide binary compatibility or POSIX compatibility, but the resulting kernel is monolithic.

现有的宏内核操作系统确实有每个组件的 API，但大多数 API 都相当复杂，因为它们是有机地发展起来的，而且组件的分离往往是模糊的，以实现性能（例如， `sendfile` 在网络和存储堆栈之间建立短路）。例如，由于历史原因，Linux 内核具有高度相互依赖的子系统\[8\]。

> Existing monolithic OSes do have APIs for each component, but most APIs are quite rich as they have evolved organically, and component separation is often blurred to achieve performance (e.g., sendfile short circuits the networking and storage stacks). The Linux kernel, for instance, historically featured highly inter-dependent subsystems \[8\].

为了更好地量化这种 API 的复杂性，我们分析了 Linux 内核的主要组件之间的依赖关系。作为一个粗略的近似，我们使用内核源代码树中的子目录来识别（广泛的）组件。我们使用 cscope 从所有内核组件的源中提取所有的函数调用，然后对每个调用进行检查，看该函数是定义在同一个组件中还是不同的组件中；对于后者，我们记为一次依赖。我们在图 1 中绘制了依赖关系图：边上的注释显示了节点之间的依赖关系的数量。这个密集的图明显表明，移除或替换 Linux 内核中的任何一个组件都需要了解并修复其他组件的所有依赖关系，这是一项艰巨的任务。

> To better quantify this API complexity, we analyzed dependencies between the main components of the Linux kernel. As a rough approximation, we used the subdirectories in the kernel source tree to identify (broad) components. We used cscope to extract all function calls from the sources of all kernel components, and then for each call checked to see if the function is defined in the same component or a different one; in the latter case, we recorded a dependency. We plot the dependency graph in Figure 1: the annotations on the edges show the number of dependencies between nodes. This dense graph makes it obvious that removing or replacing any single component in the Linux kernel requires understanding and fixing all the dependencies of other components, a daunting task.

虽然完全的模块化是困难的，但是 Rump 已经成功地将宏内核的某些部分进行了模块化。在那里，NetBSD 内核被分割成基础层（所有内核都必须使用）、由主机提供的功能（调度、内存分配等）以及可以独立运行的所谓“阵营”（例如，网络或文件系统支持）。Rump 在一定程度上实现了我们的目标，但是仍然有许多依赖性，要求所有内核都有基础层和“超调用层”（hypercall layers）。

> While full modularization is difficult, modularizing certain parts of a monolithic kernel has been done succesfully by Rump. There, the NetBSD kernel was split into base layers (which must be used by all kernels), functions provided by the host (scheduling, memory allocation,etc) and so-called factions that can be run on their own (e.g. network or filesystem support). Rump goes some way towards achieving our goals, however there are still many dependencies left which require that all kernels have the base and hypercall layers.

第二个方向是完全绕过操作系统（OS），主要是为了 I/O 性能，同时保留原有的协议栈--浪费了进程的资源。即便如此，也需要进行移植工作，因为应用程序必须针对新的网络（DPDK、netmap \[64\]或 Linux 的 io_uring \[11\]子系统）或存储（SPDK）API 进行编码。

> The second direction is to bypass the operating system (OS) altogether, mostly for I/O performance, while leaving the original stack in place – wasting resources in the process. Even here, porting effort is required as apps must be coded against the new network (DPDK, netmap \[64\] or Linux’s io_uring \[11\] subsystem) or storage (SPDK) API.

第三个方向是为每个目标应用从头开始添加所需的操作系统功能，可能通过复用现有操作系统的代码。这是 ClickOS \[51\]支持 Click 模块化路由器，MirageOS \[46\]支持 OCaml 应用，以及 MiniCache \[39\]实现网络缓存所采取的方法，仅举几例。由此产生的镜像非常精简，有很好的性能，而且启动时间小；最大的问题是，移植的工作量很大，而且大多要为每一个应用程序或语言重复进行。

> The third direction is to add the required OS functionality from scratch for each target application, possibly by reusing code from existing operating systems. This is the approach taken by ClickOS \[51\] to support Click modular routers, MirageOS \[46\] to support OCaml applications, and MiniCache \[39\] to implement a web cache, to name a few. The resulting images are very lean, have great performance and have small boot times; the big problem is that the porting effort is huge, and that it has to be mostly repeated for every single application or language.

总而言之，从现有的项目开始不是最好的选择，因为上述三个方向的项目都不是为了支持我们所概述的关键原则而设计的。我们选择从头开始设计 API，尽管我们在相关的地方重用了现有作品的组件。

> In sum, starting from an existing project is suboptimal since none of the projects in the three directions mentioned were designed to support the key principles we have outlined. We opt for a clean-slate API design approach, though we do reuse components from existing works where relevant.

## 3 Unikraft 架构和 API

> 3 Unikraft Architecture and APIs

传统的操作系统可以粗略地分为宏内核（具有很好的性能）以及能很好地隔离操作系统组件的微内核（以牺牲性能为代价）。与这些工作相比，我们的工作既包括宏式设计（组件之间没有保护）也包括微内核鼓吹的模块化。

> In contrast to classical OS work, which can be roughly split between monolithic kernels (with great performance) versus micro-kernels that provide great isolation between OS components (at the expense of performance), our work embraces both the monolithic design (no protection between components) and the modularity that micro-kernels advocated.

我们使用模块化来实现专用性，将操作系统的功能分割成细粒度的组件，这些组件只在定义明确的 API 边界内进行通信。我们的主要看法是，我们可以通过精心的 API 设计和静态链接来获得性能，而不是通过短路 API 边界来获得性能。为了实现模块化的总体原则，Unikraft 由两个主要部分组成：

> We use modularity to enable specialization, splitting OS functionality into fine-grained components that only communicate across well-defined API boundaries. Our key observation is that we can obtain performance via careful API design and static linking, rather than short-circuiting API boundaries for performance. To achieve the overarching principle of modularity, Unikraft consists of two main components:

- 微库。微库是实现 Unikraft 核心 API 之一的软件组件；我们将它们与库区分开来，因为它们具有最小的依赖性，可以是任意小的，例如一个调度器。所有实现相同 API 的微库都是可以互换的。一个这样的 API 包含多个内存分配器，它们都实现了 `ukalloc` 接口。此外，Unikraft 支持的库可以提供来自外部库项目（OpenSSL、musl、Protobuf \[31\]等）、应用程序（SQLite、Redis 等）、甚至平台（如 Solo5、Firecracker、Raspberry Pi 3）的功能。
- 构建系统。它提供了一个基于 Kconfig 的菜单，让用户选择在应用程序构建中使用哪些微库，让他们选择目标平台和 CPU 架构，甚至在需要时配置单个微库。然后，构建系统对所有的微库进行编译，将它们链接起来，并为每个选定的平台生成一个二进制文件。

> - Micro-libraries: Micro-libraries are software components which implement one of the core Unikraft APIs; we differentiate them from libraries in that they have minimal dependencies and can be arbitrarily small, e.g., a scheduler. All micro-libraries that implement the same API are interchangeable. One such API contains multiple memory allocators that all implement the ukalloc interface. In addition, Unikraft supports libraries that can provide functionality from external library projects (OpenSSL, musl, Protobuf \[31\], etc.), applications (SQLite, Redis, etc.), or even platforms (e.g., Solo5, Firecracker, Raspberry Pi 3).
> - Build system: This provides a Kconfig-based menu for users to select which micro-libraries to use in an application build, for them to select which platform(s) and CPU architectures to target, and even configure individual micro-libraries if desired. The build system then compiles all of the micro-libraries, links them, and produces one binary per selected platform.

图 4 显示了 Unikraft 的架构。所有的组件都是微库，有自己的 Makefile 和 Kconfig 配置文件，因此可以独立地添加到 unikernel 构建中^1^。API 也是微库，可以通过 Kconfig 菜单轻松启用或禁用；因此幺内核可以编排选择哪些 API，以最好地迎合应用程序的需求（例如，一个 RCP 风格的应用程序可能会关闭 `uksched` API，以实现高性能、运行到完成的事件循环）。

> Figure 4 shows Unikraft’s architecture. All components are micro-libraries that have their own Makefile and Kconfig configuration files, and so can be added to the unikernel build independently of each other^1^. APIs are also micro-libraries that can be easily enabled or disabled via a Kconfig menu; unikernels can thus compose which APIs to choose to best cater to an application’s needs (e.g., an RCP-style application might turn off the uksched API in order to implement a high performance, run-to-completion event loop).

---

1. 当然，除非一个微库依赖另一个微库，在这种情况下，构建系统也会构建该依赖。

> 1. Unless, of course, a micro-library has a dependency on another, in which case the build system also builds the dependency.

---

Unikraft 的体系结构还包括增加 POSIX 支持的组件，使其相对容易地支持现有的应用程序（更多内容见第 4 节）。Unikraft 可以通过两种方式提高应用程序的性能：

> Unikraft’s architecture also includes components that add POSIX support, making it relatively easy to support existing applications (more on this in §4). Unikraft can improve the performance of applications in two ways:

1. 未修改的应用程序，通过消除系统调用的开销，减少镜像大小和内存消耗，以及选择高效的内存分配器。
2. 专用化，通过调整应用程序，在性能至关重要的地方利用较低级别的 API（例如，寻求高磁盘 I/O 吞吐量的数据库应用程序）。

> 1. Unmodified applications, by eliminating syscall overheads, reducing image size and memory consumption, and by choosing efficient memory allocators.
> 2. Specialization, by adapting applications to take advantage of lower level APIs wherever performance is critical (e.g., a database application seeking high disk I/O throughput).

作为 Unikraft 模块化的证明，一个最小的 Hello World 配置在 KVM 上产生一个 200KB 大小的镜像，在 Xen 上产生一个 40KB 大小的镜像，只需要平台 booststrapping 代码和 nolibc——一个 Unikraft 专用的 libc 替代品，只提供基本的最小功能集，如 memcpy 和字符串处理。图 3 显示了该镜像中使用的所有库；相比之下，Linux 中（即使是）Hello World 应用也需要整个 Linux 内核。

> As a proof of Unikraft’s modularity, a minimal Hello World configuration yields an image of 200KB in size on KVM and 40KB on Xen, requiring only platform boostrapping code and nolibc, a Unikraft-specific libc replacement that only provides a basic minimal set of functionality such as memcpy and string processing. All the libraries used in this image are shown in Figure 3; in contrast, the entire Linux kernel in Figure 1 is needed for a Hello World app in Linux.

大多数应用程序确实需要更多的功能（见图 2 中的 nginx 镜像）。请注意（1）这个镜像不包括块设备子系统，因为它只使用内存文件系统，（2）所有的组件都比 Linux 对应的组件更小，依赖更少。这些例子展示了 Unikraft 轻松添加和删除组件的能力，包括核心操作系统的组件，使开发人员能够为他们的应用程序创建高效、专用的镜像。

> Most applications do require more functionality (see nginx image in Figure 2). Note how (1) this image does not include a block subsystem since it only uses RamFS, and (2) how all components are smaller and have fewer dependencies than their Linux counterparts. These examples showcase Unikraft’s ability to easily add and remove components, including core OS ones, allowing developers to create efficient, specialized images for their apps.

轻松地将组件换入和换出的能力，以及在不同层次插入应用程序的能力，为应用程序开发人员提供了广泛的优化可能性。首先，未经修改的应用程序（如 Hello World 和 nginx）可以使用musl（图 4 中的 ➀）或 nolibc 的 posix-compatibility 层，由于省略系统调用开销，透明地获得低启动时间、低内存消耗和提高吞吐量，因为 Unikraft 的系统调用实际上就是函数调用。

> The ability to easily swap components in and out, and to plug applications in at different levels presents application developers with a wide range of optimization possibilities. To begin with, unmodified applications (e.g. Hello World and nginx) can use the posix-compatibility layer with musl (➀ in Figure 4) or nolibc, transparently getting low boot times, lower memory consumption and improved throughput because of the lack of syscall overheads, as Unikraft syscalls are effectively function calls.

同样，应用程序的开发者可以很容易地选择一个合适的内存分配器（➅）来获得最大的性能，或者在同一个幺内核中使用多个不同的内存分配器（例如，一个简单、快速的内存分配器用于启动代码，而一个标准的内存分配器用于应用程序本身）。

> Likewise, the application developer can easily select an appropriate memory allocator (➅) to obtain maximum performance, or to use multiple different ones within the same unikernel (e.g., a simple, fast memory allocator for the boot code, and a standard one for the application itself).

对快速启动感兴趣的开发者可以通过提供他们自己的启动代码（➄）来遵守 `ukboot` 的 API 来进一步优化幺内核；在第 6 节中，我们展示了两个启动代码微库的实验，一个是静态内存页，一个是动态内存页，显示了启动时间和内存分配灵活性之间的折衷。

> Developers interested in fast boot times could further optimize the unikernel by providing their own boot code (➄) to comply with the ukboot API; in §6 we show experiments with two boot code micro-libraries, one with static memory pages and one with dynamic ones, showing the trade-off between boot time and memory allocation flexibility.

对于网络相关的应用，开发者可以使用标准的套接字接口（➁）或更低级、更高性能的 `uknetdev` API（➆），以显著提高吞吐量；我们将在下面更详细地讨论这个 API，并将在第 6 节评估它。同样地，数据库等受磁盘约束的应用可以通过 `vfscore` 微库（➂）遵循标准路径，或者通过对 `ukblock` API（➇）进行编码来优化吞吐量。调度器也是可插拔的（➃），每个 CPU 核可以运行不同的调度器（即使多核支持尚未完成）。

> For network-bound applications, the developers can use the standard socket interface (➁) or the lower level, higher performance uknetdev API (➆) in order to significantly improve throughput; we will discuss this API in greater detail below, and will evaluate it in §6. Similarly, disk-bound applications such as databases can follow a standard path through the vfscore micro-library (➂), or optimize throughput by coding against the ukblock API (➇). Schedulers are also pluggable (➃), and each CPU core can run a different scheduler (even if multi-core support is still work in progress).

我们将在本文后面介绍和评估其中的几个场景，但首先我们通过关注其中的一个子集，对 Unikraft 的 API 进行更深入的研究。

> We will visit and evaluate several of these scenarios later on in the paper, but first we give a more in-depth look into Unikraft’s APIs by focusing on a subset of them.

### 3.1 `uknetdev` API

> 3.1 uknetdev API

Unikraft 的网络子系统将设备驱动端（如 virtio-net、netfront）与网络堆栈或低级网络应用（简称应用）解耦。

> Unikraft’s networking sub-system decouples the device driver side (e.g., virtio-net, netfront) from the network stack or low-level networking application (application for short).

关于前者，简单地替换网络协议栈在商业操作系统中并不常见；相反，驱动程序通常是为特定的网络协议栈实现的。这个 API 的目的是将这两个组件解耦，以使驱动程序能够跨平台重用。

> Regarding the former, easily swapping network stacks is something that is not common in commodity OSes; instead, drivers are usually implemented for a particular network stack. The aim of this API is to decouple these two components in order to allow drivers to be reused across platforms.

对于后者，一个网络应用或网络协议栈应该能够在不同的平台上未经修改地运行，并对接不同的驱动程序。因为我们正在处理大量的使用案例，API 不应该限制任何一个案例，也不应该成为高性能工作负载的潜在性能瓶颈。我们从英特尔 DPDK 的 `rte_netdev` API 中获得了部分设计。然而，由于它的重点是高性能而不是高效的资源使用，我们设计了一个 API，允许应用程序在轮询、中断驱动或混合模式下操作 Unikraft 驱动程序。

> For the latter, a networking application or network stack should be able to run unmodified on a different platform with different drivers. Because we are addressing a wide range of use cases, the API should not restrict any of them nor become a potential performance bottleneck for high performance workloads. We derived part of the design from Intel DPDK’s rte_netdev API. However, because its focus is on high performance rather than efficient resource usage, we designed an API that allows applications to operate Unikraft drivers in polling, interrupt-driven, or mixed mode.

此外，`uknetdev` 将内存管理留给应用程序，同时支持高性能特性，如多队列、零拷贝 I/O 和数据包批处理。我们让应用程序完全操作和初始化驱动程序；驱动程序不会自己运行任何初始化程序。相反，我们为应用程序提供 API 接口，以提供必要的信息（例如，支持的队列数量和卸载功能），这样，应用程序代码可以通过挑选最佳的驱动程序属性和功能集来实现专用化。驱动程序将其回调（例如，发送和接收）注册到 `uk_netdev` 结构中，然后应用程序使用该结构来调用驱动程序的例程。

> In addition, uknetdev leaves memory management to the application, all the while supporting high performance features like multiple queues, zero-copy I/O, and packet batching. We let the application fully operate and initialize the driver; drivers do not run any initialization routine on their own. Instead, we provide API interfaces for applications to provide necessary information (e.g., supported number of queues and offloading features) so that the application code can specialize by picking the best set of driver properties and features. Drivers register their callbacks (e.g, send and receive) to a uk_netdev structure which the application then uses to call the driver routines.

为了开发独立于应用程序的网络驱动程序，同时使用应用程序或网络协议栈的内存管理，我们引入了一个称为 `uk_netbuf` 的网络包缓冲器包装结构。这个结构包含了驱动程序在数据包缓冲区中发送或接收数据所需的元信息；我们的想法是，应用程序使用这个结构来分配数据包缓冲区，但布局是由应用程序控制的。由于驱动程序和 API 都不管理分配，所以性能关键的工作负载可以利用预先分配的网络缓冲区池，而内存效率高的应用程序可以通过从标准堆分配缓冲区来减少内存占用。API 的发送和接收调用看起来如下。

> In order to develop application-independent network drivers while using the application’s or network stack’s memory management we introduce a network packet buffer wrapper structure called uk_netbuf. This struct contains meta information needed by the driver to send or receive data in the packet buffer; the idea is that applications use this structure for packet buffer allocations, but the layout is under the control of the application. Since neither the driver nor the API manage allocations, performance critical workloads can make use of pre-allocated network buffers pools, while memory efficient applications can reduce memory the footprint by allocating buffers from the standard heap. The send and receive calls of the API look as follows:

```c
int uk_netdev_tx_burst(struct uk_netdev *dev,
                       uint16_t queue_id,
                       struct uk_netbuf **pkt,
                       __u16 *cnt);
int uk_netdev_rx_burst(struct uk_netdev *dev,
                       uint16_t queue_id,
                       struct uk_netbuf **pkt,
                       __u16 *cnt);
```

用户交出 `uk_netbufs` 的数组并指定其长度。在发送时，驱动程序从给定的数组中尽可能多地排队等待 `netbufs`（大小是用 `cnt` 给定的）。该函数返回标志，表明队列中是否还有空间来发送更多的数据包，或者队列是否已满。`cnt` 参数也被用作输出参数，以表明有多少数据包被实际放在发送队列中。接收功能以类似的方式工作。

> The user hands over arrays of uk_netbufs and specifies their length. On transmit, the driver enqueues as many netbufs as possible from the given array (size is given with cnt). The function returns flags that indicate if there is still room on the queue to send more packets or if the queue is full. The cnt parameter is also used as an output parameter to indicate how many packets were actually placed on the send queue. The receive function works in a similar manner.

默认情况下，驱动程序以轮询模式操作队列，但 API 还有一个接口可以为特定队列启用中断模式。在这种模式下，每当函数表明没有更多的工作要做（没有更多的数据包接收或发送队列已满），队列的中断线就被启用。在驱动配置过程中，应用程序可以为每个队列注册一个中断处理程序，一旦收到数据包或发送队列的空间变得可用，该程序就被调用。之后，中断线不活动，直到发送或接收功能根据队列状态再次激活它，例如，当应用程序收到所有数据包时。数据包如何以及在哪里被接收或传输完全取决于应用程序的实现。例如，中断回调可以用来解除对接收或发送线程的封锁，但也可以包含在事件循环的实现中。一旦中断到来，应用程序就知道接收或发送函数必须被调用。这种实现方式避免了中断风暴，并能在重负载情况下自动过渡到轮询模式。

> As default, a driver operates a queue in polling mode, but the API has one more interface to enable interrupt mode for a specific queue. In this mode, whenever the function indicates that there is no more work to be done (no more packets received or the send queue is full), the interrupt line of the queue is enabled. During driver configuration the application can register an interrupt handler per queue which is called as soon as a packet is received or space becomes available on the transmit queue. Afterwards, the interrupt line is inactive until the transmit or receive function activates it again according to the queue state, for instance when all packets were received by the application. How and where packets are received or transmitted is entirely up to the application’s implementation. For instance, the interrupt callback could be used to unblock a receiving or sending thread, but could also be included into the eventloop implementations. As soon as an interrupt arrives the application knows that the receive or send function has to be called. This implementation avoids interrupt storms and enables automatic transition to polling mode under heavy load situations.

### 3.2 `ukalloc` API

> 3.2 ukalloc API

Unikraft 的内存分配子系统由三层组成：（1）一个符合 POSIX 标准的外部 API，（2）一个叫做 `ukalloc` 的内部分配 API，以及（3）一个或多个后端分配器实现。外部接口的动机是向后兼容，以方便将现有的应用程序移植到 Unikraft。在 C 语言的情况下，外部 API 由一个修改过的标准库暴露出来，这个标准库可以是 nolibc（一个最小的、针对 Unikraft 的 libc 实现）、newlib 或 musl。外部分配接口作为 Unikraft 专用的内部分配接口的兼容包装，它反过来将分配请求重定向到适当的分配器后端（每个分配器有它自己的、独立的内存区域）。因此，内部分配接口作为一个复用设施，使得在同一个幺内核中存在多个内存分配后端。

> Unikraft’s memory allocation subsystem is composed of three layers: (1) a POSIX compliant external API, (2) an internal allocation API called ukalloc, and (3) one or more backend allocator implementations. The external interface is motivated by backward compatibility to facilitate the porting of existing applications to Unikraft. In the case of the C language, the external API is exposed by a modified standard library which can be nolibc (a minimal, Unikraft-specific libc implementation), newlib or musl. The external allocation interface acts as a compatibility wrapper for the Unikraft-specific internal allocation interface, which in turn redirects allocation requests to the appropriate allocator backend (each allocator has its own, separate memory region). The internal allocation interface therefore serves as a multiplexing facility that enables the presence of multiple memory allocation backends within the same unikernel.

Unikraft 的分配接口暴露了 POSIX 接口的 `uk_` 前缀版本：`uk_malloc()`、`uk_calloc()` 等。与 POSIX 不同的是，这些函数要求调用者指定应该使用哪个分配后端来满足请求。`uk_malloc()` 的定义如下：

> Unikraft’s allocation interface exposes uk_ prefixed versions of the POSIX interface: uk_malloc(), uk_calloc(), etc. In contrast to POSIX, these functions require the caller to specify which allocation backend should be used to satisfy the request. uk_malloc() is defined as:

```c
static inline void *
uk_malloc (struct uk_alloc *a, size_t size);
```

`struct uk_alloc *` 参数代表分配后端。这个结构包含指向分配器实现 POSIX 分配接口的函数指针：`malloc()`、`calloc()`、`posix_memalign()` 等。请注意，`uk_malloc()`，像大多数内部分配接口一样，被设计成内联方法，以避免分配调用链中的任何额外的函数调用开销。

> The struct uk_alloc *argument represents the allocation backend. This structure contains function pointers that refer to the allocator’s implementation of the POSIX allocation interface: malloc(), calloc(), posix_memalign(), etc. Note that uk_malloc(), like most of the internal allocation interface, is designed as an inline method in order to avoid any additional function call overhead in the allocation path.

分配器必须指定一个初始化函数，由 `ukboot` 在启动过程的早期阶段调用。初始化函数被传递给一个指向堆的第一个可用字节的 `void*` 裸指针，以及一个指定堆大小的 `size_t len` 参数。他们必须完全初始化分配器，并在 `ukalloc` 接口注册分配器。一旦初始化函数返回，分配器就被认为可以满足内存分配的要求。启动过程设置了内存分配器和内存源之间的关联。

> Allocators must specify an initialization function which is called by ukboot at an early stage of the boot process. Initialization functions are passed a void* base pointer to the first usable byte of the heap, along with a size_t len argument which specifies the size of the heap. They must fully initialize the allocator and register the allocator with the ukalloc interface. The allocator is considered ready to satisfy memory allocations as soon as the initialization function returns. The boot process sets the association between memory allocators and memory sources.

Unikraft 支持五种分配后端：伙伴系统、两级隔离的 Fits \[53\]（TLSF）实时内存分配器、tinyalloc \[67\]、Mimalloc \[42\]（1.6.1版本）和 Oscar \[12\] 安全内存分配器。一个特殊的情况是垃圾收集（GC）内存分配器，需要一个线程来执行 GC。我们可以用两个分配器来实现这些分配器，一个用于早期启动时间，初始化 GC 线程，然后是主 GC 分配器，在其线程启动后立即接管；我们对 Mimalloc 使用这种解决方案，因为它有一个 pthread 的依赖。

> Unikraft supports five allocation backends: a buddy system, the Two-Level Segregated Fits [53] (TLSF) real-time memory allocator, tinyalloc [67], Mimalloc [42] (version 1.6.1) and the Oscar [12] secure memory allocator. A special case are garbage-collection (GC) memory allocators that require a thread to perform GC. We can implement these with two allocators, one for the early boot time that initializes the GC thread, and then the main GC allocator, which takes over as soon as its thread is started; we use this solution for Mimalloc because it has a pthread dependency.

### 3.3 `uksched` 和 `uklock` API

> 3.3 uksched and uklock APIs

与许多操作系统不同，Unikraft 中的调度是可有可无的；这使得构建轻量级单线程的幺内核或运行到完成的幺内核成为可能，避免了由负载内的调度器引起的抖动。示例的用例是提供作为虚拟机（如驱动域）或虚拟网络功能（VNF）的支持功能。

> Unlike many OSes, scheduling in Unikraft is available but optional; this enables building lightweight single-threaded unikernels or run-to-completion unikernels, avoiding the jitter caused by a scheduler within the guest. Example use cases are to provide support functions as virtual machines (as in driver domains), or Virtual Network Functions (VNFs).

与 `ukalloc` 类似，`uksched` 抽象了实际的调度器接口。平台库只提供了基本的机制，如上下文切换和计时器，因此调度逻辑和算法是通过实际的调度器库来实现的（截至目前，Unikraft 支持协作式和抢占式调度器）。

> Similar to ukalloc, uksched abstracts actual scheduler interfaces. The platform library provides only basic mechanisms like context switching and timers so that scheduling logic and algorithms are implemented with an actual scheduler library (Unikraft supports co-operative and pre-emptive schedulers as of this writing).

此外，Unikraft 支持实例化多个调度器，例如，每个可用的虚拟 CPU 或可用 CPU 的子集有一个调度器。以 VNF 为例，由于性能和延迟的原因，人们可以在运行数据面处理的虚拟核心上选择无调度或合作调度，但为控制面选择一个共同的抢占式调度器。

> Additionally, Unikraft supports instantiating multiple schedulers, for example one per available virtual CPU or for a subset of available CPUs. For VNFs for example, one may select no scheduling or cooperative scheduling on virtual cores that run the data plane processing because of performance and delay reasons, but select a common preemptive scheduler for the control plane.

`uklock` 库提供了同步原语，如互斥锁和信号量。为了保持其他库的代码可移植性，`uklock` 会根据幺内核的配置方式选择目标实现。这两个方面是线程和多核支持。在最简单的情况下（无线程和单核），一些原语可以在编译时被完全移除，因为不需要互斥机制。如果启用了多核（我们还不支持），一些原语将使用自旋锁和 RCU，因此在这种情况下它们会被编译进去。

> The uklock library provides synchronization primitives such as mutexes and semaphores. In order to keep the code of other libraries portable, uklock selects a target implementation depending on how the unikernel is configured. The two dimensions are threading and multi-core support. In the simplest case (no threading and single core), some of the primitives can be completely compiled out since there is no need for mutual exclusion mechanisms. If multi-core were enabled (we do not yet support this), some primitives would use spin-locks and RCUs, and so in this case they would be compiled in.

## 4 应用程序支持和移植

> 4 Application Support and Porting

可以说，一个操作系统只有在它能够实际运行应用程序时才是好的；从一开始，这就成为了幺内核的一根刺，因为它们经常需要人工移植应用程序。近期的一些工作研究了二进制兼容性，即在运行时将未经修改的二进制文件和系统调用翻译成幺内核的底层功能\[37, 54\]。这种方法的优点是不需要移植工作，但是翻译会带来严重的性能损失。

> Arguably, an OS is only as good as the applications it can actually run; this has been a thorn on unikernels’ side since their inception, since they often require manual porting of applications. More recent work has looked into using binary compatibility, where unmodified binaries are taken and syscalls translated, at run-time, into a unikernel’s underlying functionality [37, 54]. This approach has the advantage of requiring no porting work, but the translation comes with important performance penalties.

为了量化这些，表 1 显示了在英特尔 i7 9700K 3.6 GHz CPU 和 Linux 5.11 上运行的微测试的结果，这些测试比较了空（NOP）系统调用和函数调用的在 Unikraft 和 Linux 上的成本（Unikraft 带有运行时系统调用翻译）。Unikraft 中带有运行时翻译的系统调用比 Linux 中快 2-3 倍（取决于是否启用 KPTI 和其他侧信道攻击缓解措施）。然而，与函数调用相比，具有运行时翻译的系统调用具有十倍的性能成本，使得像 OSv、Rump 和 HermiTux \[36, 37, 54\]中所做的二进制兼容变得昂贵。

> To quantify these, Table 1 shows the results of microbenchmarks ran on an Intel i7 9700K 3.6 GHz CPU and Linux 5.11 that compare the cost of no-op system and function calls in Unikraft and Linux (with run-time syscall translation for Unikraft). System calls with run-time translation in Unikraft are 2-3x faster than in Linux (depending on whether KPTI and other mitigations are enabled). However, system calls with run-time translation have a tenfold performance cost compared to function calls, making binary compatibility as done in OSv, Rump and HermiTux [36, 37, 54] expensive.

对于运行单个应用程序的虚拟机来说，系统调用可能不值得它们的成本，因为 Hypervisor 也提供了隔离。在这种情况下，幺内核可以通过消除用户/内核隔离及其相关成本来获得重要的性能优势。二进制兼容的间接调用大大降低了幺内核的好处。

> For virtual machines running a single application, syscalls are likely not worth their costs, since isolation is also offered by the hypervisor. In this context, unikernels can get important performance benefits by removing the user/kernel separation and its associated costs. The indirection used by binary compatibility reduces unikernel benefits significantly.

为了避免这些劣势，但仍然尽量减少移植工作，我们采取了一种不同的方法：我们依靠目标应用程序的原生构建系统，并将静态编译的对象文件链接到 Unikraft 的最终链接步骤中。为了达到这个目的，我们移植了 musl C 标准库，因为它在很大程度上与 glibc 兼容，但更节省资源，还有 newlib，因为它通常用于构建幺内核。

> To avoid these penalties but still minimize porting effort, we take a different approach: we rely on the target application’s native build system, and use the statically-compiled object files to link them into Unikraft’s final linking step. For this to work, we ported the musl C standard library, since it is largely glibc-compatible but more resource efficient, and newlib, since it is commonly used to build unikernels.

为了支持依赖 Linux 系统调用的 musl，我们创建了一个叫做系统调用 shim 的微库：每个实现系统调用处理程序的库都通过一个宏注册到这个微库中。然后，shim 层在 libc 级生成一个系统调用接口。通过这种方式，我们可以在用 Unikraft 编译应用程序源文件时直接链接到系统调用的实现，结果是系统调用被转化为廉价的函数调用。

> To support musl, which depends on Linux syscalls, we created a micro-library called syscall shim: each library that implements a system call handler registers it, via a macro, with this micro-library. The shim layer then generates a system call interface at libc-level. In this way, we can link to system call implementations directly when compiling application source files natively with Unikraft, with the result that syscalls are transformed into inexpensive function calls.

表 2 显示了在针对 musl 和 newlib 进行构建时，在一些不同的应用程序和库上尝试这种方法的结果：这种方法对 newlib \[2\]无效（“std” 列），但对 musl 有效：大多数库都能完全自动构建。对于那些不能构建的库，其原因与使用 glibc 特定的符号有关（注意，newlib 不是这种情况，其中许多 glibc 函数根本就没有实现）。为了解决这个问题，我们在一系列 musl 补丁\[56\]和其他 20 个我们手工实现的函数（主要是 64 位版本的文件操作，如 `pread` 或 `pwrite`）的基础上建立了一个 glibc 兼容层。

> Table 2 shows results when trying this approach on a number of different applications and libraries when building against musl and newlib: this approach is not effective with newlib \[2\] ("std" column), but it is with musl: most libraries build fully automatically. For those that do not, the reason has to do with the use of glibc-specific symbols (note that this is not the case with newlib, where many glibc functions are not implemented at all). To address this, we build a glibc compatibility layer based on a series of musl patches [56] and 20 other functions that we implement by hand (mostly 64-bit versions of file operations such as pread or pwrite).

有了这个，如表所示（“兼容层”一栏），这个层允许几乎所有的库和应用程序进行编译和链接。对于 musl 来说，这是一个好消息：只要应用程序工作所需的系统调用被实现，那么镜像就会成功运行（对于 newlib，stub 必须被实现）。

> With this in place, as shown in the table ("compat layer" column), this layer allows for almost all libraries and applications to compile and link. For musl that is good news: as long as the syscalls needed for the applications to work are implemented, then the image will run successfully (for newlib the stubs would have to be implemented).

### 4.1 应用程序兼容性

> 4.1 Application Compatibility

Unikraft 支持多少系统调用？截至目前，我们有 146 个系统调用的实现；根据相关工作\[54, 74\]，在 100-150 个系统调用的区域内，足以运行丰富的主流应用程序、框架和语言；我们在表 3 中确认了这一点，该表列出了 Unikraft 目前支持的软件。

> How much syscall support does Unikraft have? As of this writing, we have implementations for 146 syscalls; according to related work \[54, 74\], in the region of 100-150 syscalls are enough to run a rich set of mainstream applications, frameworks and languages; we confirm this in Table 3, which lists software currently supported by Unikraft.

除此以外，我们对支持更多的应用程序可能需要多少工作进行了简短的分析。我们使用 Debian 人气竞赛数据\[14\]来选择一组最受欢迎的 30 个服务器应用程序（例如，apache、mongodb、postgres、avahi、bind9）。为了得出这些应用程序实际运行所需的一套准确的系统调用，并将以前的工作\[61\]中所做的静态分析扩展为动态分析，我们创建了一个由各种配置（例如，网络服务器的不同端口号、后台模式等）和单元测试（例如，数据库服务器的 SQL 查询、DNS 服务器的 DNS 查询等）组成的小框架。然后，这些配置和单元测试被作为输入给分析器，分析器依靠 strace 工具来监控应用程序的行为。一旦完成了动态分析，就将结果与静态分析的结果进行比较和补充。

> Beyond this, we conduct a short analysis of how much more work it might take to support additional applications. We use the Debian popularity contest data \[14\] to select a set of the 30 most popular server applications (e.g., apache, mongodb, postgres, avahi, bind9). To derive an accurate set of syscalls these applications require to actually run, and to extend the static analysis done in previous work \[61\] with dynamic analysis, we created a small framework consisting of various configurations (e.g., different port numbers for web servers, background mode, etc.) and unit tests (e.g., SQL queries for database servers, DNS queries for DNS servers, etc.). These configurations and unit tests are then given as input to the analyzer which monitors the application’s behavior by relying on the strace utility. Once the dynamic analysis is done, the results are compared and added to the ones from the static analysis.

我们将结果与我们的系统目前支持的系统调用绘制在图 5 的热图中（整个分析和热图的生成由我们开发的一套工具完全自动化）。每个方块代表一个单独的系统调用，编号从 0（`read`）到 313（`finit_module`）。浅色的方块是没有任何应用程序需要的（在刻度上为 0）或很少的应用程序（20%）；黑色的方块（例如，方块 1，`write`）是所有应用程序都需要的。方块上的数字意味着 Unikraft 支持某个系统调用，而空方块则表示还不支持某个系统调用。

> We plot the results against the syscalls currently supported by our system in the heatmap on Figure 5 (the entire analysis and heatmap generation is fully automated by a set of tools we developed). Each square represents an individual syscall, numbered from 0 (read) to 313 (finit_module). Lightly colored squares are required by none of the applications (0 on the scale) or few of them (20% of them); black squares (e.g., square 1, write) are required by all. A number on a square means that a syscall is supported by Unikraft, and an empty square is a syscall not supported yet.

从热图上可以看出，要支持流行的应用程序，一半以上的系统调用甚至都不需要，而且大部分需要的系统调用我们已经支持了。在那些不被支持的系统调用中（大约有 60 个）。

> As can be seen from the map, more than half the syscalls are not even needed in order to support popular applications, and most of the needed syscalls we already support. Of those that are not supported (in the order of about 60):

- 有几个可以在单核环境下快速 stub（例如，`getcpu`，如果使用单个 cpu）。
- 许多是相对容易实现的，因为必要的功能已经被 Unikraft 支持（例如，`semget`/`semopt`/`semctl`）。
- 其余的是正在进行的工作（如 epoll，eventfd）。

> - several can be quickly stubbed in a unikernel context (e.g., getcpu, if using a single cpu);
> - many are relatively trivial to implement since the necessary functionality is already supported by Unikraft (e.g., semget/semopt/semctl).
> - and the rest are work in progress (e.g., epoll, eventfd).

为了进一步量化这一点，图 7 显示了在所选的 30 个应用程序中，到目前为止 Unikraft 支持多少他们需要的系统调用（绿色），如果我们在所有 30 个应用程序中实现接下来的 5 个最常见的系统调用（黄色），接下来的 10 个（浅蓝色），一直到完全支持，我们将多么接近完全支持。第一个收获是，所有的应用程序都接近于完全支持（图中大部分是绿色的）。第二点需要注意的是，即使是我们正在运行的应用程序也不全是绿色的（例如 SQLite、nginx）：这是因为许多应用程序即使在某些系统调用被 stub 或返回 `ENOSYS` 的情况下也能工作（如果缺少一个系统调用的实现，我们的 shim 层会自动这样做）。我们目前正在进行一项调查，以了解有多少这样的应用程序可以实际运行，尽管其条形图不是完全绿色的。

> To quantify this even further, Figure 7 plots, for each of the selected 30 applications, how much of their needed syscalls Unikraft supports so far (in green), how close to full support we would be if we implemented the next 5 most common syscalls across all 30 applications (yellow), the next 10 (light blue), all the way to full support. The first take-away is that all applications are close to having full support (the graph is mostly green). The second thing to note is that even applications that we do have running are not all green (e.g., SQLite, nginx): this is because many applications work even if certain syscalls are stubbed or return ENOSYS (which our shim layer automatically does if a syscall implementation is missing). We are currently in the process of conducting a survey of how many of these applications can actually run despite their bars not being completely green.

我们估计，为支持这些缺失的系统调用而进行的适度的额外工程工作将带来对应用程序更广泛的支持。最后，对于无法获得源代码的情况，Unikraft 也支持二进制兼容性和二进制重写，正如 HermiTux \[54\]中所做的。

> We estimate that a moderate level of additional engineering work to support these missing syscalls would result in even wider support for applications. Finally, for cases where the source code is not available, Unikraft also supports binary compatibility and binary rewriting as done in HermiTux \[54\].

### 4.2 手动移植

> 4.2 Manual Porting

当自动化方法不奏效，而性能又是最重要的，所以二进制兼容不是一个选项时，我们依靠手动移植。然而，请注意，由于 Unikraft 的微库为建立专门的技术栈提供了一个共同的代码基础，这样的手工移植比过去的幺内核项目（包括我们自己的工作）耗费的时间要少得多；这一点从我们在移植各种库和应用时需要添加的几行胶水代码中可以看出（见表 2，最后一列）。

> When the automated approach does not work and performance is paramount so binary compatibility is not an option, we rely on manual porting. Note, however, that because Unikraft’s micro-libraries provide a common code base for building specialized stacks, such manual porting is significantly less time consuming than that of past unikernels projects (including our own work) that take in the order of months to be put together; this is clear from the few lines of glue code we needed to add when porting a wide range of libraries and applications (see Table 2, last column).

事实上，在 Unikraft 的整个生命周期中，一些传闻指出，随着通用代码库的成熟，移植额外的功能变得越来越容易。诚然，量化移植一个库所花费的实际工时是一项困难的工作（例如，由于提交时间戳可能会掩盖这样一个事实，即在移植一个库的过程中，大量的时间被用于移植它的一个依赖项）。尽管如此，我们还是对项目开源社区中所有移植过库或应用程序的开发者（约 70 人）进行了调查，并在此展示结果。特别是，我们要求开发者大致计算一下移植一个实际的库或应用程序所花费的时间，移植库的依赖关系（例如，memcached 需要 libevent）所花费的时间，以及实现缺失的操作系统基元（例如，`poll()` 函数）或向 Unikraft 的构建系统添加功能所花费的时间。我们使用 `git commit history` 来追踪一个移植的开始时间。

> In fact, anecdotal accounts throughout the lifetime of Unikraft point to the fact that, as the common code base has matured, porting additional functionality has gotten increasingly easier. Admittedly, quantifying the actual man hours spent porting a library is a difficult exercise (e.g., because commit timestamps may hide the fact that, during the course of porting a library, significant time was spent porting one of its dependencies). Nevertheless, we have conducted a survey of all developers in the project’s open source community (around 70) who have ported a library or application, and present the results here. In particular, we asked developers to roughly calculate the time it took to port an actual library or application, the time it took to port library dependencies (e.g., memcached requires libevent), and the time it took to implement missing OS primitives (e.g., the poll() function) or add functionality to Unikraft’s build system. We use git commit history to track when a port was started.

为了显示移植工作随着项目的成熟所发生的变化，我们在图 6 中以时间线的形式绘制了从 2019 年 3 月开始到 2020 年 5 月结束的调查结果；为了便于表述，我们进一步将结果按季度分组。该图证实了传闻中的证据，即随着时间的推移，开发人员不得不花时间移植依赖关系或实现缺失的操作系统基元的时间明显减少。

> To show the evolution of the porting effort as the project matured, we plot the results of the survey in a time-line starting in March 2019 and ending in May 2020 in Figure 6; for ease of presentation, we further group the results in quarters. The figure confirms the anecdotal evidence that, as time progressed, the amount of time developers had to spend porting dependencies or implementing missing OS primitives has significantly decreased.

最后，Unikraft 对各种语言及其环境（标准库、垃圾收集器等）的支持意味着一些基于这些语言的项目（如英特尔的 DNNL/C++、Django/Python、Ruby on Rails/Ruby 等）应该可以开箱即用。

> Finally, Unikraft’s support for a wide range of languages and their environments (standard libraries, garbage collectors, etc.) means that a number of projects based on these (e.g., Intel’s DNNL/C++, Django/Python, Ruby on Rails/Ruby, etc.) should work out of the box.

## 5 基础评估

> 5 Base Evaluation

Unikraft 的主要目标是帮助开发者快速、轻松地创建轻量、高性能的幺内核。在这一节中，我们将评估 Unikraft 在多大程度上透明地实现了这一目标，即无需修改应用程序（基本上是图 4 中架构图中的方案 1-3）；然后，在第 6 节中，我们将评估为遵守 Unikraft 的 API 而进行的（轻微）修改如何能够带来更高的性能。

> The main goal of Unikraft is to help developers quickly and easily create resource-efficient, high-performance unikernels. In this section we evaluate to what extent Unikraft achieves this goal transparently, i.e., without having to modify applications (essentially scenarios 1-3 in the architecture diagram in Figure 4); then, in Section 6 we will evaluate how (slight) modifications to comply with Unikraft’s APIs can result in even higher performance.

在整个评估过程中，我们使用 KVM 作为虚拟化平台。Unikraft 也支持 Xen 和裸机目标（例如 Raspberry Pi 和 Xilinx Ultra96-V2），但我们把它们的性能评估留给未来的工作。我们在一台廉价的（大约 800 欧元）Shuttle SH370R6 电脑上运行所有的实验，该电脑配备了英特尔 i7 9700K 3.6 GHz（4.9 Ghz with Turbo Boost，8 个核心）和 32GB 内存。在 DPDK 实验中，我们使用两台通过直连线连接的电脑和一对 82599EB 芯片组的英特尔 X520-T2 网卡。

> Throughout our evaluation, we use KVM as the virtualization platform. Unikraft also supports Xen and bare-metal targets (e.g., Raspberry Pi and Xilinx Ultra96-V2), but we leave their performance evaluation to future work. We run all experiments on an inexpensive (roughly €800) Shuttle SH370R6 computer with an Intel i7 9700K 3.6 GHz (4.9 Ghz with Turbo Boost, 8 cores) and 32GB of RAM. For the DPDK experiment we use two of these connected via a direct cable and a pair of Intel X520-T2 cards with the 82599EB chipset.

此外，我们禁用了超线程，并使用内核启动参数（`isolcpus=4-7 noht`）为主机隔离了 4 个 CPU 核心；从剩下的 4 个 CPU 核心中，我们将一个钉在虚拟机上，另一个钉在 VMM（如qemu-system）上，还有一个钉在客户端工具（如 wrk 或 redis-benchmark）上，并将 governor 设置为性能。最后，对于 Xen 启动实验，我们使用 Xen 4.0 版本。

> Further, we disabled Hyper-Threading and isolated 4 CPU cores for the host using kernel boot parameters (isolcpus=4-7 noht); from the remaining 4 CPU cores we pinned one to the VM, another one to the VMM (e.g., qemu-system), and another one to the client tool (e.g., wrk or redis-benchmark), and set the governor to performance. Finally, for the Xen boot experiments we use Xen version 4.0.

---

> **TODO** *governor* 是什么东西？

---

所有的实验都是通过将一个 CPU 核钉在虚拟机上，另一个钉在 VMM（如 qemu-system）上，另一个钉在客户端工具（如 wrk 或 redis-benchmark）上；禁用超线程；并将治理器设置为性能。

> All experiments were conducted by pinning a CPU core to the VM, another one to the VMM (e.g., qemu-system), and another one to the client tool (e.g., wrk or redis-benchmark); by disabling Hyper-threading; and by setting the governor to performance.

### 5.1 资源效率：越小越好

> 5.1 Resource Efficiency: Smaller is Better

与传统操作系统相比，幺内核的主要优势在于其低资源消耗。这体现在磁盘上的二进制镜像大小，以及运行时的启动时间和内存占用。我们在 Unikraft 中对一些有代表性的应用程序进行了评估，并与领先的幺内核和 Linux 进行了比较。我们的结果显示在图 8 至 11。

> The main advantage of unikernels over traditional OSes is their low resource consumption. This is reflected in binary image size when on disk, and boot-time and memory footprint at runtime. We evaluated these for a number of representative apps in Unikraft, in comparison with leading unikernels, and Linux. Our results are shown in figs. 8 to 11.

为了量化 Unikraft 中的镜像大小，我们为 DCO 和 LTE 的所有组合，以及 helloworld 虚拟机和其他三个应用：nginx、Redis 和 SQLite 生成了一些镜像。图 8 中的结果显示，对于所有这些应用，Unikraft 镜像都在 2MB 以下。我们在图 9 中进一步将这些结果与其他幺内核和 Linux 进行比较。如图所示，Unikraft 镜像比所有其他幺内核项目都要小，并且与 Linux 用户空间二进制文件相当（注意，Linux 的尺寸只是应用程序的尺寸；它们不包括 glibc 和内核的尺寸）。这是 Unikraft 的模块化方法的结果，大大减少了需要编译和链接的代码量（例如，对于 helloworld，不需要调度器和内存分配器）。

> In order to quantify image sizes in Unikraft, we generate a number of images for all combinations of DCO and LTE, and for a helloworld VM and three other applications: nginx, Redis and SQLite. The results in Figure 8 show that Unikraft images are all under 2MBs for all of these applications. We further compare these results with other unikernels and Linux in Figure 9. As shown, Unikraft images are smaller than all other unikernel projects and comparable to Linux userspace binaries (note that the Linux sizes are just for the application; they do not include the size of glibc nor the kernel). This is a consequence of Unikraft’s modular approach, drastically reducing the amount of code to be compiled and linked (e.g., for helloworld, no scheduler and no memory allocator are needed).

小尺寸的镜像不仅有利于最小化磁盘存储，也有利于快速启动。LightVM \[48\]表明，使用高度优化的 Xen 工具链，可以在 2ms 左右启动一个空（NOP）的幺内核。在我们的评估中，我们使用标准的虚拟化工具栈代替，并希望了解 Unikraft 虚拟机的启动速度。在运行实验时，我们既测量 VMM（例如 Firecracker、QEMU、Solo5）所花费的时间，也测量实际幺内核/虚拟机的启动时间，从运行第一条客户指令到调用 `main()` 的时间。

> Small image sizes are not only useful for minimizing disk storage, but also for quick boot times. LightVM \[48\] has shown that it is possible to boot a no-op unikernel in around 2ms, with a heavily optimized Xen toolstack. In our evaluation, we use standard virtualization toolstacks instead, and wish to understand how quickly Unikraft VMs can boot. When running experiments, we measure both the time taken by the VMM (e.g. Firecracker, QEMU, Solo5) and the boot time of the actual unikernel/VM, measured from when the first guest instruction is run until main() is invoked.

结果如图10所示，显示了一个 helloworld 幺内核在不同的 VMM 下需要多长时间启动。Unikraft 在 QEMU 和 Solo5 上的启动时间（只有虚拟机，没有 VMM 开销）从几十（没有网卡）到几百微秒（有网卡）不等。在 Firecracker 上，启动时间稍长，但不超过 1ms。这些结果与以前的工作相比是积极的。MirageOS（在 Solo5 上为 1-2ms），OSv（在 Firecracker 上为 4-5ms，带有只读文件系统），Rump（在 Solo5 上为 14-15ms），Hermitux（在 uHyve 上为 30-32ms），Lupine（在 Firecracker 上为 70ms，没有 KML 为 18ms），和 Alpine Linux（在 Firecracker 上约为 330ms）。这说明 Unikraft 能够只保留和初始化需要的东西。

> The results are shown in Figure 10, showing how long a helloworld unikernel needs to boot with different VMMs. Unikraft’s boot time on QEMU and Solo5 (guest only, without VMM overheads) ranges from tens (no NIC) to hundreds of microseconds (one NIC). On Firecracker, boot times are slightly longer but do not exceed 1ms. These results compare positively to previous work: MirageOS (1-2ms on Solo5), OSv (4-5ms on Firecracker with a read-only filesystem), Rump (14-15ms on Solo5), Hermitux (30-32ms on uHyve), Lupine (70ms on Firecracker, 18ms without KML), and Alpine Linux (around 330ms on Firecracker). This illustrates Unikraft’s ability to only keep and initialize what is needed.

总的来说，总的虚拟机启动时间由 VMM 主导，Solo5 和 Firecracker 最快（3ms），QEMU microVM 约 10ms，QEMU 最慢，约 40ms（我们在图 14 和 21 中详细阐述了客户启动时间）。这些结果表明，Unikraft 可以随时用于需要及时实例化虚拟机的场景。

> Overall, the total VM boot time is dominated by the VMM, with Solo5 and Firecracker being the fastest (3ms), QEMU microVM at around 10ms and QEMU the slowest at around 40ms (we elaborate on guest boot times in figs. 14 and 21). These results show that Unikraft can be readily used in scenarios where just-in-time instantiation of VMs is needed.

最后，以前的工作\[48\]不仅强调了快速实例化的重要性，也强调了虚拟机密度的重要性。为了了解当内存是一个瓶颈时，我们可以在一台服务器上打包多少个幺内核虚拟机，我们进行了实验来测量将各种应用作为幺内核启动所需的最小内存量，发现 2-6MB 的内存对 Unikraft 虚拟机来说已经足够了（图 11）。

> Finally, previous work \[48\] stressed the importance of not only fast instantiation but also VM density. In order to understand how many unikernel VMs we could pack on a single server when RAM is a bottleneck, we ran experiments to measure the minimum amount of memory required to boot various applications as unikernels, finding that 2-6MBs of memory suffice for Unikraft guests (Figure 11).
